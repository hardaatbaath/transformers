# Transformer
This is the implementation of the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762). 
The code has been written in Google Colab, so make the necessary changes to the scripts to run them.
Thanks to [Umar Jamilai](https://www.youtube.com/@umarjamilai) and his videos on the topic, they were extremely helpful and a valuable resource.

More comments will be added in the future to make the process of understanding the code easier.

## Execution:
You can use the **requiremets.txt** file to run it on your computer or use the **colab_train.ipynb** to run it on Google Colab
<br>
To run on Colab, remember to add the files **config.py, data.py, model.py, train.py**

## Citation:
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. (2017). 
*Attention Is All You Need*. 
[ArXiv.](https://arxiv.org/abs/1706.03762)
