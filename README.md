# Transformer
This is the implementation of the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762). 
The code has been written in Python, so make the necessary changes to the scripts to run them.
Thanks to [Umar Jamilai](https://www.youtube.com/@umarjamilai) and his videos on the topic, they were extremely helpful and valuable.

More comments will be added in the future to make the process of understanding the code easier.

I have used the opus_books dataset for this code.

## Citation:
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. (2017). 
*Attention Is All You Need*. 
[ArXiv.](https://arxiv.org/abs/1706.03762)
